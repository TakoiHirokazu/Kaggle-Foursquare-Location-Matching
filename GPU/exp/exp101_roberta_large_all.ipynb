{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T02:05:30.440496Z",
     "iopub.status.busy": "2022-05-16T02:05:30.439885Z",
     "iopub.status.idle": "2022-05-16T02:05:37.372907Z",
     "shell.execute_reply": "2022-05-16T02:05:37.372111Z",
     "shell.execute_reply.started": "2022-05-16T02:05:30.440453Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-24 21:14:13.666935: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Library\n",
    "# =========================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sys, os\n",
    "from transformers import DistilBertModel, DistilBertTokenizer,AutoModel,AutoTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from sklearn.model_selection import GroupKFold, KFold, StratifiedKFold\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import logging\n",
    "import sys\n",
    "from contextlib import contextmanager\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import cudf, cuml, cupy\n",
    "from cuml.feature_extraction.text import TfidfVectorizer\n",
    "from cuml.neighbors import NearestNeighbors\n",
    "import gc\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T02:05:37.375136Z",
     "iopub.status.busy": "2022-05-16T02:05:37.374755Z",
     "iopub.status.idle": "2022-05-16T02:05:37.380182Z",
     "shell.execute_reply": "2022-05-16T02:05:37.379140Z",
     "shell.execute_reply.started": "2022-05-16T02:05:37.375095Z"
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Constant\n",
    "# =========================\n",
    "TRAIN_PATH = \"../data/train.csv\"\n",
    "TARGET = \"point_of_interest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T02:05:37.381872Z",
     "iopub.status.busy": "2022-05-16T02:05:37.381599Z",
     "iopub.status.idle": "2022-05-16T02:05:37.444538Z",
     "shell.execute_reply": "2022-05-16T02:05:37.443795Z",
     "shell.execute_reply.started": "2022-05-16T02:05:37.381837Z"
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Settings\n",
    "# =========================\n",
    "exp = \"101\"\n",
    "if not os.path.exists(f\"../output/exp/ex{exp}\"):\n",
    "    os.makedirs(f\"../output/exp/ex{exp}\")\n",
    "    os.makedirs(f\"../output/exp/ex{exp}/model\")\n",
    "LOGGER_PATH = f\"../output/exp/ex{exp}/ex_{exp}.txt\"\n",
    "MODEL_PATH_BASE = f\"../output/exp/ex{exp}/model/ex{exp}\"\n",
    "MODEL_PATH = \"xlm-roberta-large\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "val_fold = 0 \n",
    "# config\n",
    "SEED = 0\n",
    "BATCH_SIZE = 64\n",
    "iters_to_accumulate = 1\n",
    "n_epochs = 5\n",
    "max_len = 128\n",
    "weight_decay = 0.1\n",
    "beta = (0.9, 0.98)\n",
    "lr = 1e-5\n",
    "num_warmup_steps_rate = 0.1\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "clip_grad_norm = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============\n",
    "# Functions\n",
    "# ===============\n",
    "def setup_logger(out_file=None, stderr=True, stderr_level=logging.INFO, file_level=logging.DEBUG):\n",
    "    LOGGER.handlers = []\n",
    "    LOGGER.setLevel(min(stderr_level, file_level))\n",
    "\n",
    "    if stderr:\n",
    "        handler = logging.StreamHandler(sys.stderr)\n",
    "        handler.setFormatter(FORMATTER)\n",
    "        handler.setLevel(stderr_level)\n",
    "        LOGGER.addHandler(handler)\n",
    "\n",
    "    if out_file is not None:\n",
    "        handler = logging.FileHandler(out_file)\n",
    "        handler.setFormatter(FORMATTER)\n",
    "        handler.setLevel(file_level)\n",
    "        LOGGER.addHandler(handler)\n",
    "\n",
    "    LOGGER.info(\"logger set up\")\n",
    "    return LOGGER\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s')\n",
    "    \n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T02:05:37.447731Z",
     "iopub.status.busy": "2022-05-16T02:05:37.447033Z",
     "iopub.status.idle": "2022-05-16T02:05:37.460693Z",
     "shell.execute_reply": "2022-05-16T02:05:37.459912Z",
     "shell.execute_reply.started": "2022-05-16T02:05:37.447684Z"
    }
   },
   "outputs": [],
   "source": [
    "class FourSquareDataset(Dataset):\n",
    "    def __init__(self, text, near_text,num_features, tokenizer, max_len,labels=None):\n",
    "        self.text = text\n",
    "        self.near_text = near_text\n",
    "        self.num_features = num_features\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = self.text[item]\n",
    "        near_text = self.near_text[item]\n",
    "        inputs = self.tokenizer(\n",
    "            text,near_text,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        num_feature = self.num_features[item]\n",
    "        if self.labels is not None:\n",
    "            label = self.labels[item]\n",
    "            return {\n",
    "                \"input_ids\": torch.tensor(ids, dtype=torch.long),\n",
    "                \"attention_mask\": torch.tensor(mask, dtype=torch.long),\n",
    "                \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n",
    "                \"num_feature\" : torch.tensor(num_feature, dtype=torch.float32),\n",
    "                \"label\" : torch.tensor(label, dtype=torch.float32),\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"input_ids\": torch.tensor(ids, dtype=torch.long),\n",
    "                \"attention_mask\": torch.tensor(mask, dtype=torch.long),\n",
    "                \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n",
    "                \"num_feature\" : torch.tensor(num_feature, dtype=torch.float32),\n",
    "            }\n",
    "    \n",
    "    \n",
    "class bert_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(bert_model, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(MODEL_PATH)\n",
    "        self.ln1 = nn.LayerNorm(1024)\n",
    "        self.linear1 = nn.Sequential(\n",
    "            nn.Linear(1024,128),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2))\n",
    "        \n",
    "        self.linear2 = nn.Sequential(\n",
    "            nn.Linear(2,32),\n",
    "            nn.LayerNorm(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2))\n",
    "        \n",
    "        self.linear3 = nn.Sequential(\n",
    "            nn.Linear(128 + 32,64),\n",
    "            nn.LayerNorm(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64,1),\n",
    "           )\n",
    "        \n",
    "    \n",
    "\n",
    "    def forward(self, ids, mask, token_type_ids,num_features):\n",
    "        # pooler\n",
    "        out = self.model(ids, attention_mask=mask,token_type_ids=token_type_ids)['last_hidden_state'][:,0,:]\n",
    "        out =  self.ln1(out)\n",
    "        out = self.linear1(out)\n",
    "        out2 = self.linear2(num_features)\n",
    "        out = torch.cat([out,out2],axis=-1)\n",
    "        out = self.linear3(out)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "def collate(d,train=True):\n",
    "    mask_len = int(d[\"attention_mask\"].sum(axis=1).max())\n",
    "    if train:\n",
    "        return {\"input_ids\" : d['input_ids'][:,:mask_len],\n",
    "                \"attention_mask\" : d['attention_mask'][:,:mask_len],\n",
    "                \"token_type_ids\" : d[\"token_type_ids\"][:,:mask_len],\n",
    "                 \"label\" : d['label'],\n",
    "                 \"num_feature\" : d[\"num_feature\"]}\n",
    "    else:\n",
    "        return {\"input_ids\" : d['input_ids'][:,:mask_len],\n",
    "                \"attention_mask\" : d['attention_mask'][:,:mask_len],\n",
    "                \"token_type_ids\" : d[\"token_type_ids\"][:,:mask_len],\n",
    "                 \"num_feature\" : d[\"num_feature\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/columbia2131/foursquare-iou-metrics\n",
    "def get_id2poi(input_df: pd.DataFrame) -> dict:\n",
    "    return dict(zip(input_df['id'], input_df['point_of_interest']))\n",
    "\n",
    "def get_poi2ids(input_df: pd.DataFrame) -> dict:\n",
    "    return input_df.groupby('point_of_interest')['id'].apply(set).to_dict()\n",
    "\n",
    "def get_score(input_df: pd.DataFrame):\n",
    "    scores = []\n",
    "    for id_str, matches in zip(input_df['id'].to_numpy(), input_df['matches'].to_numpy()):\n",
    "        targets = poi2ids[id2poi[id_str]]\n",
    "        preds = set(matches.split())\n",
    "        score = len((targets & preds)) / len((targets | preds))\n",
    "        scores.append(score)\n",
    "    scores = np.array(scores)\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-24 21:14:25,698 - INFO - logger set up\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<RootLogger root (DEBUG)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOGGER = logging.getLogger()\n",
    "FORMATTER = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "setup_logger(out_file=LOGGER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T02:05:37.462347Z",
     "iopub.status.busy": "2022-05-16T02:05:37.462014Z",
     "iopub.status.idle": "2022-05-16T02:05:44.599422Z",
     "shell.execute_reply": "2022-05-16T02:05:44.598528Z",
     "shell.execute_reply.started": "2022-05-16T02:05:37.462307Z"
    }
   },
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Main\n",
    "# ============================\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "train_fold0 = pd.read_csv(\"../output/exp/ex062/ex062_pred.csv\")\n",
    "train_fold1 = pd.read_csv(\"../output/exp/ex063/ex063_pred.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nameとcategoryのみ\n",
    "train_near = train.copy()\n",
    "train_near.columns = [f\"near_{i}\" for i in train.columns]\n",
    "use_cols = [\"name\",\"categories\",'latitude', 'longitude','address','city','state']\n",
    "near_use_cols = [f\"near_{c}\" for c in use_cols]\n",
    "train_fold0 = train_fold0.merge(train[[\"id\"] + use_cols],how=\"left\",on=\"id\")\n",
    "train_fold0 = train_fold0.merge(train_near[[\"near_id\"] + near_use_cols],how=\"left\",on=\"near_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fold1 = train_fold1.merge(train[[\"id\"] + use_cols],how=\"left\",on=\"id\")\n",
    "train_fold1 = train_fold1.merge(train_near[[\"near_id\"] + near_use_cols],how=\"left\",on=\"near_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-24 21:14:46,845 - INFO - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2022-06-24 21:14:46,846 - INFO - NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "# textの作成\n",
    "train_fold0[\"text\"] = train_fold0['name'].astype(str).str.lower() + \" \" + train_fold0['categories'].astype(str).str.lower()+\\\n",
    "                      train_fold0['address'].astype(str).str.lower() + \" \" + train_fold0['city'].astype(str).str.lower() + \" \" + train_fold0['state'].astype(str).str.lower() \n",
    "train_fold0[\"near_text\"] = train_fold0['near_name'].astype(str).str.lower() + \" \" + train_fold0['near_categories'].astype(str).str.lower()+\\\n",
    "                      train_fold0['near_address'].astype(str).str.lower() + \" \" + train_fold0['near_city'].astype(str).str.lower() + \" \" + train_fold0['near_state'].astype(str).str.lower() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# textの作成\n",
    "train_fold1[\"text\"] = train_fold1['name'].astype(str).str.lower() + \" \" + train_fold1['categories'].astype(str).str.lower()+\\\n",
    "                      train_fold1['address'].astype(str).str.lower() + \" \" + train_fold1['city'].astype(str).str.lower() + \" \" + train_fold1['state'].astype(str).str.lower() \n",
    "train_fold1[\"near_text\"] = train_fold1['near_name'].astype(str).str.lower() + \" \" + train_fold1['near_categories'].astype(str).str.lower()+\\\n",
    "                      train_fold1['near_address'].astype(str).str.lower() + \" \" + train_fold1['near_city'].astype(str).str.lower() + \" \" + train_fold1['near_state'].astype(str).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latitude mean: 26.87459868745177 std 23.144740576788625\n",
      "longitude mean: 20.70497351331466 std 82.6778436146614\n"
     ]
    }
   ],
   "source": [
    "# sc\n",
    "for c in [\"latitude\",\"longitude\"]:\n",
    "    mean = train[c].mean()\n",
    "    std = train[c].std()\n",
    "    train_fold0[f\"{c}_sc\"] = (train_fold0[c] - mean) / std\n",
    "    train_fold1[f\"{c}_sc\"] = (train_fold1[c] - mean) / std\n",
    "    print(c,\"mean:\",mean,\"std\",std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['latitude_sc', 'longitude_sc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all = pd.concat([train_fold0,train_fold1]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============start epoch:0==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "100%|██████████| 66309/66309 [4:04:53<00:00,  4.51it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============start epoch:1==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66309/66309 [4:05:01<00:00,  4.51it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============start epoch:2==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66309/66309 [4:04:57<00:00,  4.51it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============start epoch:3==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66309/66309 [4:03:27<00:00,  4.54it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============start epoch:4==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66309/66309 [4:05:20<00:00,  4.50it/s]  \n",
      "2022-06-25 17:39:56,771 - INFO - [roberta] done in 73473 s\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# train\n",
    "# ================================\n",
    "with timer(\"roberta\"):\n",
    "    set_seed(SEED)\n",
    "    train_text,train_near_text, train_num_features, train_labels = \\\n",
    "    train_all[\"text\"].values, train_all[\"near_text\"].values,train_all[num_cols].values, train_all[\"target\"].values\n",
    "        \n",
    "    train_ = FourSquareDataset(train_text,train_near_text,train_num_features,\n",
    "                               tokenizer,max_len,train_labels)\n",
    "        \n",
    "    # loader\n",
    "    train_loader = DataLoader(dataset=train_, batch_size=BATCH_SIZE, shuffle = True ,pin_memory=True,num_workers=8)\n",
    "        \n",
    "    # model\n",
    "    model = bert_model()\n",
    "    model = model.to(device)\n",
    "\n",
    "    # optimizer, scheduler\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                      lr=lr,\n",
    "                      betas=beta,\n",
    "                      weight_decay=weight_decay,\n",
    "                      )\n",
    "    num_train_optimization_steps = int(len(train_loader) * n_epochs)\n",
    "    num_warmup_steps = int(num_train_optimization_steps * num_warmup_steps_rate)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=num_warmup_steps,\n",
    "                                                num_training_steps=num_train_optimization_steps)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    best_score = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f\"============start epoch:{epoch}==============\")\n",
    "        model.train() \n",
    "        scaler = GradScaler()\n",
    "        for i, d in tqdm(enumerate(train_loader),total=len(train_loader)):\n",
    "            d = collate(d)\n",
    "            ids = d[\"input_ids\"].to(device)\n",
    "            mask = d['attention_mask'].to(device)\n",
    "            token_type_ids = d[\"token_type_ids\"].to(device)\n",
    "            labels = d['label'].to(device)\n",
    "            num_features = d[\"num_feature\"].to(device)\n",
    "            labels = labels.unsqueeze(-1)\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                output = model(ids,mask,token_type_ids,num_features)\n",
    "                loss = criterion(output, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            #torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad_norm)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "        torch.save(model.state_dict(), MODEL_PATH_BASE + f\"_{epoch}.pth\") # Saving current best model\n",
    "        if epoch == 4:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
