{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T02:05:30.440496Z",
     "iopub.status.busy": "2022-05-16T02:05:30.439885Z",
     "iopub.status.idle": "2022-05-16T02:05:37.372907Z",
     "shell.execute_reply": "2022-05-16T02:05:37.372111Z",
     "shell.execute_reply.started": "2022-05-16T02:05:30.440453Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 20:43:12.066053: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Library\n",
    "# =========================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sys, os\n",
    "from transformers import DistilBertModel, DistilBertTokenizer,AutoModel,AutoTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from sklearn.model_selection import GroupKFold, KFold, StratifiedKFold\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score,recall_score,precision_score\n",
    "import logging\n",
    "import sys\n",
    "from contextlib import contextmanager\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import cudf, cuml, cupy\n",
    "from cuml.feature_extraction.text import TfidfVectorizer\n",
    "from cuml.neighbors import NearestNeighbors\n",
    "import gc\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T02:05:37.375136Z",
     "iopub.status.busy": "2022-05-16T02:05:37.374755Z",
     "iopub.status.idle": "2022-05-16T02:05:37.380182Z",
     "shell.execute_reply": "2022-05-16T02:05:37.379140Z",
     "shell.execute_reply.started": "2022-05-16T02:05:37.375095Z"
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Constant\n",
    "# =========================\n",
    "TRAIN_PATH = \"../data/train.csv\"\n",
    "TARGET = \"point_of_interest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T02:05:37.381872Z",
     "iopub.status.busy": "2022-05-16T02:05:37.381599Z",
     "iopub.status.idle": "2022-05-16T02:05:37.444538Z",
     "shell.execute_reply": "2022-05-16T02:05:37.443795Z",
     "shell.execute_reply.started": "2022-05-16T02:05:37.381837Z"
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Settings\n",
    "# =========================\n",
    "exp = \"113\"\n",
    "if not os.path.exists(f\"../output/exp/ex{exp}\"):\n",
    "    os.makedirs(f\"../output/exp/ex{exp}\")\n",
    "    os.makedirs(f\"../output/exp/ex{exp}/model\")\n",
    "LOGGER_PATH = f\"../output/exp/ex{exp}/ex_{exp}.txt\"\n",
    "MODEL_PATH_BASE = f\"../output/exp/ex{exp}/model/ex{exp}\"\n",
    "MODEL_PATH = \"xlm-roberta-large\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "val_fold = 0 \n",
    "# config\n",
    "SEED = 0\n",
    "BATCH_SIZE = 64\n",
    "iters_to_accumulate = 1\n",
    "n_epochs = 5\n",
    "max_len = 128\n",
    "weight_decay = 0.1\n",
    "beta = (0.9, 0.98)\n",
    "lr = 1e-5\n",
    "num_warmup_steps_rate = 0.1\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "clip_grad_norm = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============\n",
    "# Functions\n",
    "# ===============\n",
    "def setup_logger(out_file=None, stderr=True, stderr_level=logging.INFO, file_level=logging.DEBUG):\n",
    "    LOGGER.handlers = []\n",
    "    LOGGER.setLevel(min(stderr_level, file_level))\n",
    "\n",
    "    if stderr:\n",
    "        handler = logging.StreamHandler(sys.stderr)\n",
    "        handler.setFormatter(FORMATTER)\n",
    "        handler.setLevel(stderr_level)\n",
    "        LOGGER.addHandler(handler)\n",
    "\n",
    "    if out_file is not None:\n",
    "        handler = logging.FileHandler(out_file)\n",
    "        handler.setFormatter(FORMATTER)\n",
    "        handler.setLevel(file_level)\n",
    "        LOGGER.addHandler(handler)\n",
    "\n",
    "    LOGGER.info(\"logger set up\")\n",
    "    return LOGGER\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s')\n",
    "    \n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T02:05:37.447731Z",
     "iopub.status.busy": "2022-05-16T02:05:37.447033Z",
     "iopub.status.idle": "2022-05-16T02:05:37.460693Z",
     "shell.execute_reply": "2022-05-16T02:05:37.459912Z",
     "shell.execute_reply.started": "2022-05-16T02:05:37.447684Z"
    }
   },
   "outputs": [],
   "source": [
    "class FourSquareDataset(Dataset):\n",
    "    def __init__(self, text, near_text,num_features, tokenizer, max_len,labels=None):\n",
    "        self.text = text\n",
    "        self.near_text = near_text\n",
    "        self.num_features = num_features\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = self.text[item]\n",
    "        near_text = self.near_text[item]\n",
    "        inputs = self.tokenizer(\n",
    "            text,near_text,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        num_feature = self.num_features[item]\n",
    "        if self.labels is not None:\n",
    "            label = self.labels[item]\n",
    "            return {\n",
    "                \"input_ids\": torch.tensor(ids, dtype=torch.long),\n",
    "                \"attention_mask\": torch.tensor(mask, dtype=torch.long),\n",
    "                \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n",
    "                \"num_feature\" : torch.tensor(num_feature, dtype=torch.float32),\n",
    "                \"label\" : torch.tensor(label, dtype=torch.float32),\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"input_ids\": torch.tensor(ids, dtype=torch.long),\n",
    "                \"attention_mask\": torch.tensor(mask, dtype=torch.long),\n",
    "                \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n",
    "                \"num_feature\" : torch.tensor(num_feature, dtype=torch.float32),\n",
    "            }\n",
    "    \n",
    "    \n",
    "class bert_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(bert_model, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(MODEL_PATH)\n",
    "        self.ln1 = nn.LayerNorm(1024)\n",
    "        self.linear1 = nn.Sequential(\n",
    "            nn.Linear(1024,128),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2))\n",
    "        \n",
    "        self.linear2 = nn.Sequential(\n",
    "            nn.Linear(2,32),\n",
    "            nn.LayerNorm(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2))\n",
    "        \n",
    "        self.linear3 = nn.Sequential(\n",
    "            nn.Linear(128 + 32,64),\n",
    "            nn.LayerNorm(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64,1),\n",
    "           )\n",
    "        \n",
    "    \n",
    "\n",
    "    def forward(self, ids, mask, token_type_ids,num_features):\n",
    "        # pooler\n",
    "        out = self.model(ids, attention_mask=mask,token_type_ids=token_type_ids)['last_hidden_state'][:,0,:]\n",
    "        out =  self.ln1(out)\n",
    "        out = self.linear1(out)\n",
    "        out2 = self.linear2(num_features)\n",
    "        out = torch.cat([out,out2],axis=-1)\n",
    "        out = self.linear3(out)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "def collate(d,train=True):\n",
    "    mask_len = int(d[\"attention_mask\"].sum(axis=1).max())\n",
    "    if train:\n",
    "        return {\"input_ids\" : d['input_ids'][:,:mask_len],\n",
    "                \"attention_mask\" : d['attention_mask'][:,:mask_len],\n",
    "                \"token_type_ids\" : d[\"token_type_ids\"][:,:mask_len],\n",
    "                 \"label\" : d['label'],\n",
    "                 \"num_feature\" : d[\"num_feature\"]}\n",
    "    else:\n",
    "        return {\"input_ids\" : d['input_ids'][:,:mask_len],\n",
    "                \"attention_mask\" : d['attention_mask'][:,:mask_len],\n",
    "                \"token_type_ids\" : d[\"token_type_ids\"][:,:mask_len],\n",
    "                 \"num_feature\" : d[\"num_feature\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/columbia2131/foursquare-iou-metrics\n",
    "def get_id2poi(input_df: pd.DataFrame) -> dict:\n",
    "    return dict(zip(input_df['id'], input_df['point_of_interest']))\n",
    "\n",
    "def get_poi2ids(input_df: pd.DataFrame) -> dict:\n",
    "    return input_df.groupby('point_of_interest')['id'].apply(set).to_dict()\n",
    "\n",
    "def get_score(input_df: pd.DataFrame):\n",
    "    scores = []\n",
    "    for id_str, matches in zip(input_df['id'].to_numpy(), input_df['matches'].to_numpy()):\n",
    "        targets = poi2ids[id2poi[id_str]]\n",
    "        preds = set(matches.split())\n",
    "        score = len((targets & preds)) / len((targets | preds))\n",
    "        scores.append(score)\n",
    "    scores = np.array(scores)\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 20:43:23,812 - INFO - logger set up\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<RootLogger root (DEBUG)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOGGER = logging.getLogger()\n",
    "FORMATTER = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "setup_logger(out_file=LOGGER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T02:05:37.462347Z",
     "iopub.status.busy": "2022-05-16T02:05:37.462014Z",
     "iopub.status.idle": "2022-05-16T02:05:44.599422Z",
     "shell.execute_reply": "2022-05-16T02:05:44.598528Z",
     "shell.execute_reply.started": "2022-05-16T02:05:37.462307Z"
    }
   },
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Main\n",
    "# ============================\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "train_fold0_pp = pd.read_csv(\"../output/exp/ex113/ex113_pp_new_pair_fold0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nameとcategoryのみ\n",
    "train_near = train.copy()\n",
    "train_near.columns = [f\"near_{i}\" for i in train.columns]\n",
    "use_cols = [\"name\",\"categories\",'latitude', 'longitude','address','city','state']\n",
    "near_use_cols = [f\"near_{c}\" for c in use_cols]\n",
    "train_fold0_pp = train_fold0_pp.merge(train[[\"id\"] + use_cols],how=\"left\",on=\"id\")\n",
    "train_fold0_pp = train_fold0_pp.merge(train_near[[\"near_id\"] + near_use_cols],how=\"left\",on=\"near_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 20:43:44,572 - INFO - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2022-07-07 20:43:44,572 - INFO - NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "# textの作成\n",
    "train_fold0_pp[\"text\"] = train_fold0_pp['name'].astype(str).str.lower() + \" \" + train_fold0_pp['categories'].astype(str).str.lower()+\\\n",
    "                      train_fold0_pp['address'].astype(str).str.lower() + \" \" + train_fold0_pp['city'].astype(str).str.lower() + \" \" + train_fold0_pp['state'].astype(str).str.lower() \n",
    "train_fold0_pp[\"near_text\"] = train_fold0_pp['near_name'].astype(str).str.lower() + \" \" + train_fold0_pp['near_categories'].astype(str).str.lower()+\\\n",
    "                      train_fold0_pp['near_address'].astype(str).str.lower() + \" \" + train_fold0_pp['near_city'].astype(str).str.lower() + \" \" + train_fold0_pp['near_state'].astype(str).str.lower() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latitude mean: 26.87459868745177 std 23.144740576788625\n",
      "longitude mean: 20.70497351331466 std 82.6778436146614\n"
     ]
    }
   ],
   "source": [
    "# sc\n",
    "for c in [\"latitude\",\"longitude\"]:\n",
    "    mean = train[c].mean()\n",
    "    std = train[c].std()\n",
    "    train_fold0_pp[f\"{c}_sc\"] = (train_fold0_pp[c] - mean) / std\n",
    "    #train_fold1[f\"{c}_sc\"] = (train_fold1[c] - mean) / std\n",
    "    print(c,\"mean:\",mean,\"std\",std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['latitude_sc', 'longitude_sc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 2782/2782 [03:20<00:00, 13.89it/s]\n",
      "2022-07-07 20:47:45,759 - INFO - [roberta] done in 235 s\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# train\n",
    "# ================================\n",
    "with timer(\"roberta\"):\n",
    "    set_seed(SEED)\n",
    "    val_text,val_near_text, val_num_features, val_labels = \\\n",
    "    train_fold0_pp[\"text\"].values, train_fold0_pp[\"near_text\"].values,train_fold0_pp[num_cols].values, train_fold0_pp[\"target\"].values\n",
    "    val_ = FourSquareDataset(val_text,val_near_text,val_num_features,\n",
    "                             tokenizer,max_len,val_labels)\n",
    "        \n",
    "    val_loader = DataLoader(dataset=val_, batch_size=BATCH_SIZE*2, shuffle = False , pin_memory=True,num_workers=8)\n",
    "        \n",
    "    # model\n",
    "    model = bert_model()\n",
    "    model.load_state_dict(torch.load(\"../output/exp/ex070/model/ex070_0.pth\"))\n",
    "    model = model.to(device)\n",
    "\n",
    "    val_preds = []\n",
    "    model.eval()  # switch model to the evaluation mode\n",
    "    with torch.no_grad():  \n",
    "        for d in tqdm(val_loader,total=len(val_loader)):\n",
    "            # =========================\n",
    "            # data loader\n",
    "            # =========================\n",
    "            d = collate(d)\n",
    "            ids = d[\"input_ids\"].to(device)\n",
    "            mask = d['attention_mask'].to(device)\n",
    "            token_type_ids = d[\"token_type_ids\"].to(device)\n",
    "            num_features = d[\"num_feature\"].to(device)\n",
    "            with autocast():\n",
    "                outputs = model(ids,mask,token_type_ids,num_features)\n",
    "            val_preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "    val_preds = np.concatenate(val_preds,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"../output/exp/ex{exp}/oof.npy\",val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fold0_pp[\"pred\"] = val_preds.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6090026230502649"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fold0_pp[\"target\"].sum()/len(train_fold0_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7846234209742918"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(train_fold0_pp[\"target\"],train_fold0_pp[\"pred\"] > 0.02)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
